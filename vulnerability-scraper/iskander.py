from bs4 import BeautifulSoup

import os
import re
import json
import logging
import time
import argparse
import requests
import sqlite3

class Iskander():
	pass

class Database(Iskander):
	"""

	"""

	def __init__(self, database="iskander.db"):
		self.DATABASE = database

	def connect(self):
		try:
			connection = sqlite3.connect(self.DATABASE)
			return connection
		except:
			raise Exception("Unable to open database")

	def init_database(self):
		try:
			connection = self.connect()
			cursor = connection.cursor()
			cursor.execute('''CREATE TABLE patchstack
               (id INTEGER PRIMARY KEY, record_type TEXT, slug TEXT, name TEXT, version TEXT, report_date TEXT, vulnerability TEXT, cvss TEXT)''')
			connection.commit()
			connection.close()
		except:
			raise Exception("Unable to create base data")

	def get_records(self, record_type, slug, name, version, report_date, vulnerability, cvss=None):
		try:
			connection = self.connect()
			cursor = connection.cursor()
			cursor.execute("SELECT * FROM patchstack WHERE record_type = ? AND slug = ? AND name = ? AND version = ? AND report_date = ? AND vulnerability = ? AND cvss IS ?", (record_type, slug, name, version, report_date, vulnerability, cvss, ))

			results = cursor.fetchall()
			connection.close()
			return results
		except:
			raise Exception("Unable to get data") 

	def add_record(self, record_type, slug, name, version, report_date, vulnerability, cvss=None):
		try:
			connection = self.connect()
			cursor = connection.cursor()
			cursor.execute("INSERT INTO patchstack VALUES (NULL, ?, ?, ?, ?, ?, ?, ?)", (record_type, slug, name, version, report_date, vulnerability, cvss, ))
			connection.commit()
			connection.close()
		except:
			raise Exception("Unable to insert new data") 

class Patchstack(Iskander):
	"""

	"""

	def __init__(self):
		logging.basicConfig(level=logging.DEBUG, format="%(asctime)s - %(message)s")

	def filter_page_html(self, html):
		plugins = {}
		soup = BeautifulSoup(html, "html.parser")

		for article in soup.find_all("article"):
			slug = article.a["href"].split("/")[-1]

			lines = article.text.split("\n")
			non_empty_lines = [line for line in lines if line.strip() != ""]

			# Sanitise data and remove spaces
			# non = [x.strip() for x in non_empty_lines]
			# print(slug, non)

			if len(non_empty_lines) == 4:
				plugin = {"name": non_empty_lines[0].strip(),
						  "version": non_empty_lines[2].replace("<=", "").strip(),
						  "report_date": non_empty_lines[3].strip(),
						  "vulnerability": "",
						  "cvss": None,
						  "record_type": non_empty_lines[1].strip().lower()}

				if slug not in plugins:
					plugins[slug] = [plugin]
				else:
					plugins[slug].append(plugin)

			elif len(non_empty_lines) == 5:
				plugin = {"name": non_empty_lines[0].strip(),
						  "version": non_empty_lines[3].strip().replace("<=", "").strip(),
						  "report_date": non_empty_lines[4].strip(),
						  "vulnerability": non_empty_lines[1].strip(),
						  "cvss": None,
						  "record_type": non_empty_lines[2].strip().lower()}

				if slug not in plugins:
					plugins[slug] = [plugin]
				else:
					plugins[slug].append(plugin)

			elif len(non_empty_lines) == 9:
				plugin = {"name": non_empty_lines[0].strip(),
						  "version": non_empty_lines[7].strip().replace("<=", "").strip(),
						  "report_date": non_empty_lines[8].strip(),
						  "vulnerability": non_empty_lines[3].strip(),
						  "cvss": non_empty_lines[2].strip(),
						  "record_type": non_empty_lines[6].strip().lower()}

				if slug not in plugins:
					plugins[slug] = [plugin]
				else:
					plugins[slug].append(plugin)

			else:
				raise Exception("article element not found in HTML")

		return plugins

	def get_page(self, page):
		headers = {
			'authority': 'patchstack.com',
			'cache-control': 'max-age=0',
			'sec-ch-ua': '" Not;A Brand";v="99", "Google Chrome";v="97", "Chromium";v="97"',
			'sec-ch-ua-mobile': '?0',
			'sec-ch-ua-platform': '"macOS"',
			'upgrade-insecure-requests': '1',
			'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.99 Safari/537.36',
			'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',
			'sec-fetch-site': 'same-origin',
			'sec-fetch-mode': 'navigate',
			'sec-fetch-user': '?1',
			'sec-fetch-dest': 'document',
			'accept-language': 'en-GB,en;q=0.9,en-US;q=0.8,et;q=0.7,es;q=0.6',
			'cookie': '',
		}
		params = (
			('search', ''),
			('page', page),
			#('type', 'plugin'),
			('type', 'all'),
			('exact', 'false'),
			)
		response = requests.get("https://patchstack.com/database/", headers=headers, params=params)

		return response.text

	def get_pages(self, pages):
		html = ""
		for page in pages:
			html += self.get_page(page)
			time.sleep(3)

		return html

if __name__ == "__main__":
	patchstack = Patchstack()
	pages = patchstack.get_pages([x for x in reversed(range(18, 30))])

	slugs = patchstack.filter_page_html(pages)
	database = Database()

	if not os.path.exists("iskander.db"):
		database.init_database()

	for slug, slug_data in slugs.items():
		for item in slug_data:
			existing_data = database.get_records(item["record_type"], slug, item["name"], item["version"], item["report_date"], item["vulnerability"], item["cvss"])
			if not existing_data:
				logging.info(f"[+] New record: {item['record_type']}, {slug}, {item['name']}, {item['version']}, {item['report_date']}, {item['vulnerability']}, {item['cvss']}")
				database.add_record(item["record_type"], slug, item["name"], item["version"], item["report_date"], item["vulnerability"], item["cvss"])
			else:
				logging.info(f"[X] Existing record: {item['record_type']}, {slug}, {item['name']}, {item['version']}, {item['report_date']}, {item['vulnerability']}, {item['cvss']}")
